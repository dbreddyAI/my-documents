{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Basic notation <br>\n",
    "${x_j}^{(i)}$ means, ith record, jth feature <br>\n",
    "Two things about gradient descent:1 feature scaling or mean normalization; 2 learning rate<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "gradient decent\n",
    "$\\theta$ is (m+1,1) vector, x is (m+1,1) vector, \n",
    "$$h = \\sum_{i=0}^{m} \\theta_i x_i = \\theta ^T x $$\n",
    "loss function \n",
    "$$ L = 1/2 \\sum_{j=0}^{n-1}(f_j(w) - y_j)^2$$\n",
    "**gradient decent**\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial (\\theta_j)} $$\n",
    "where l is the learning rate. <br>\n",
    "\n",
    "gradient of loss function if only one sample.\n",
    "$$\\frac{\\partial L}{\\partial (w_k)} = (f_j - y_j)\\frac{\\partial}{\\partial (w_k)} \\sum_{i=0}^{m-1}w_ix_i  $$\n",
    "$$ = (f_j - y_j)x_k  $$\n",
    "If using all samples information(batch gradient)\n",
    "$$ w_k = w_k - l \\sum_{i=0}^{m-1}(f_i -y_i)x_k   $$\n",
    "If only one sample. for every sample i, the weight get updated\n",
    "$$ w_k = w_k - l (f_i -y_i)x_k   $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "scale <br>\n",
    "- **feature scaling**: <br>\n",
    "$$ \\frac{x}{max - min}$$\n",
    "different features take similar scale (about -1<= x <=1). It helps gradient descent converge quicker. (e.g. the shape of the loss function contour will be regular shape if they have similar scale)<br>\n",
    "- **mean normalization**: <br>\n",
    "$$ \\frac{x- \\mu}{\\sigma} $$ or $$ \\frac{x- \\mu}{max - min} $$ <br>\n",
    "3. it is important for especially **polynomial model**. \n",
    "\n",
    "**learning rate**<br>\n",
    "checking if gradient decent works? plot cost function vs iteration\n",
    "- **observation**:for i iteration, got the weights, plug in cost function, then see plot of the cost function vs iteration to check if it works. \n",
    "- **auto stop**, calculate the change of cost function, if it is less than the threshold, then stop \n",
    "- if it goes up, it means not converging, it also indicate of **too large learning rate**.  \n",
    "- if learning rate is small enough, J can converge. but too small learning rate takes too long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h3> Logistic regression </h3>\n",
    "adding sigmoid function \n",
    "$$z = \\theta ^T x $$ \n",
    "$$h(z) = \\frac{1}{1+ e^{-z}}$$\n",
    "h(z) is from 0 to 1, very similar to probability p(z). <br>\n",
    "\n",
    "- **Decision boundary**, setting thredhold to be 0.5, which means h(z) > 0.5, we classify to be Class 1. This is equal to say we classify to be Class 1 when z > 0 or $\\theta ^ T x > 0 $. The hyperplane $\\theta^Tx=0$ will form a linear decision boundary on on the x plane. Notice that the decision boundary the property of $\\theta$ not x.<br>\n",
    "When using polynomial form, we can get a **non-linear** decision boundary like a circle $ 1 < x_1^2 + x_2^2 $ using $(1,x_1,x_2,x_1^2,x_2^2)$ as our predictor space. <br>\n",
    "\n",
    "- ** Solving**: not directly using least sqaure fit on h(z), because it is now become non-convex problem due to sigmoid function ( many local minimums). <br>\n",
    "Cost function ( using maximum likelyhood)<br>\n",
    "$$J(\\theta) = 1/m \\sum_i^m [(y^{(i)} \\log h(x^{(i)}) + (1-y^{(i)}) \\log (1-h(x^{(i)}))]$$\n",
    "Gradient decent<br> \n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial (\\theta_j)} $$\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial (\\theta_j)} = \\frac{1}{m} \\sum_i^m (h(x^{(i)})-y^{(i)})x_j^{(i)} $$\n",
    "<br>\n",
    "- **regulization**ï¼šregulate the weights similar to linear regression, no regulate for bias term \n",
    "     $$J(\\theta) = 1/m \\sum_{i=1}^m [(y^{(i)} \\log h(x^{(i)}) + (1-y^{(i)}) \\log (1-h(x^{(i)}))] + \\frac{\\lambda}{2m}\\sum_{j=1}^n\\theta_j^2$$\n",
    "     $$\\frac{\\partial J(\\theta)}{\\partial (\\theta_j)} = \\frac{1}{m} \\sum_i^m (h(x^{(i)})-y^{(i)})x_j^{(i)} + \\frac{\\lambda}{m}\\theta_j $$\n",
    "     where i is the index of record, **j start from 1 not from 0**\n",
    "- **Advanced optimization**\n",
    "\n",
    "```matlab\n",
    "function [jVal, gradient] = costFunction(theta)\n",
    "% to compute jVal and its gradient\n",
    "\n",
    "% Call the function by \n",
    "options = optimset('GradObj', 'on', 'MaxIter', 100);\n",
    "initialTheta = zeros(2,1);\n",
    "[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);\n",
    "```\n",
    "- ** multi-class**<br>\n",
    "one-versus-all: given n classes, train n different logistic regression model, select the maxmimum output class as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h3> Neural network </h3>\n",
    "**The structure of neural network**\n",
    "- The input is x with size [3,1], first layer weights $\\Theta^{(1)} $size is [4,5], as the bias term is added in x; the hidden layer is [5,1]. Set the second weights  $\\Theta^{(2)}$ is [6,1], the output size is [1,1] for simple-classification problem.   \n",
    "- **dimension**<br> \n",
    "    $s_j$ units in layer j and $s_{j+1}$ units in layer j+1, then $\\Theta^{(i)}$ is $s_{j+1}*(s_j +1)$\n",
    "- **expresion in vector** <br>\n",
    "    $$ z^{(j+1)} = \\Theta^{(j)}a^{(j)}$$\n",
    "    $$ a^{(j+1)} = g(z^{(j+1)})$$\n",
    "    where g is the activation function, $x = [x_0, x_1, ...x_n]^T, z=[z_1, z_2,...z_m]^T$<br>\n",
    "    similar the code expression\n",
    "    \n",
    "    ```python\n",
    "        a[j+1] = sigmoid(Theta[j].dot(a[i]))\n",
    "        #a[j+1] is 1-d vector , Theta[j] is 2-d matrix\n",
    "    ```  \n",
    "- **cost function** for K output class <br> \n",
    "    $$J(\\theta) = 1/m \\sum_{i=1}^m \\sum_{k=1}^K [(y_k^{(i)} \\log (h(x^{(i)}))_k + (1-y_k^{(i)}) \\log (1-(h(x^{(i)}))_k)] + \\frac{\\lambda}{2m}\\sum_{l=1}^{L-1}\\sum_{i=1}^{s_l} \\sum_{j=1}^{s_{l+1}}  (\\Theta_{ji}^{(l)})^2$$\n",
    "    Similar to logistic regression, First term is sum over all K outputs, second term is sum for all weights from layer 1 to layer L-1, each layer has dimension of [$s_{l+1}$,$s_l$]\n",
    "- **back propogation** <br>\n",
    "    compute $$- \\frac{\\partial}{\\partial \\Theta_{ji}^{(l)}} J(\\Theta) $$\n",
    "\n",
    "    - algorithm: \n",
    "        - loop through each record, forward propogation, then backward propogation \n",
    "        - for backpropogation, computer error term (not the actual derivative) for each layer $\\delta^{l}$ vector, each term is determined by previous term:\n",
    "         $$ \\delta^{(L)} = a^{(L)} - y^{(true)}$$ a is after activation, z is before activation<br>\n",
    "         $\\delta^{l}$ is the partitial derivative of cost with respect to z,\n",
    "         $$\\delta^{l} = \\frac{\\partial}{\\partial z_j^{(l)}} \\text{cost(i)}$$\n",
    "         for other layer [L-1 to 2]  (no 1 as we don't have error term for input layer) \n",
    "         $$ \\delta^{(l)} = (\\Theta^{(l)})^T\\delta^{(l+1)} .* g^\\prime(z^{(l)})$$ where .* is element-wise product <br>\n",
    "         This is to propogate previous error term l+1 through l weights, then through activation function l,  so back through weights to reach a, then through activation function to z.<br> \n",
    "        - if using sigmoid function  \n",
    "          $$ g^\\prime(z^{(l)}) = a^{(l)} .* (1-a^{(l)}) $$\n",
    "        - update or you may think of as sum of each derivative \n",
    "        $$ \\Delta_{ij}^{(l)}: = \\Delta_{ij}^{(l)} + a_j^{(l)} \\delta_i^{(l+1)} $$ \n",
    "       \n",
    "        $a_j^{(l)} \\delta_i^{(l+1)}$ is the partial derivative for one record\n",
    "        - outside the loop, update the actual partial derivative for record 1-m, adding regulization for weights \n",
    "           $$\\frac{\\partial}{\\partial \\Theta_{ji}^{(l)}} J(\\Theta) = D_{ij}^{(l)}:= \\frac{1}{m}(\\Delta_{ij}^{(l)} + \\lambda \\Theta{ij}^{(l)})  $$ when j = 0, no regulization term\n",
    "- In element-wise expression, for second element in layer 3, $a_1^{(3)}$\n",
    "  $$ a_1^{(3)} = g(\\Theta_{1,0}^{(2)}a_0^{(2)} + \\Theta_{1,1}^{(2)}a_1^{(2)} + \\Theta_{1,2}^{(2)}a_2^{(2)} )$$\n",
    "- reason to use multiple-layer is to approximate complex function. such as XOR funtion needed to be approximate by two layers\n",
    "One-vs-All for multiple-class problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h3> Matlab </h3>\n",
    "matrix 2x2 matrix: x =[[1,2];[3,4]] <br>\n",
    "extend one column of b: x=[a[:,1],b[:,2]]  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
