{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Basic notation <br>\n",
    "${x_j}^{(i)}$ means, ith record, jth feature <br>\n",
    "Two things about gradient descent:1 feature scaling or mean normalization; 2 learning rate<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "gradient decent\n",
    "$\\theta$ is (m+1,1) vector, x is (m+1,1) vector, \n",
    "$$h = \\sum_{i=0}^{m} \\theta_i x_i = \\theta ^T x $$\n",
    "loss function \n",
    "$$ L = 1/2 \\sum_{j=0}^{n-1}(f_j(w) - y_j)^2$$\n",
    "**gradient decent**\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial (\\theta_j)} $$\n",
    "where l is the learning rate. <br>\n",
    "\n",
    "gradient of loss function if only one sample.\n",
    "$$\\frac{\\partial L}{\\partial (w_k)} = (f_j - y_j)\\frac{\\partial}{\\partial (w_k)} \\sum_{i=0}^{m-1}w_ix_i  $$\n",
    "$$ = (f_j - y_j)x_k  $$\n",
    "If using all samples information(batch gradient)\n",
    "$$ w_k = w_k - l \\sum_{i=0}^{m-1}(f_i -y_i)x_k   $$\n",
    "If only one sample. for every sample i, the weight get updated\n",
    "$$ w_k = w_k - l (f_i -y_i)x_k   $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "scale <br>\n",
    "1. **feature scaling**: <br>\n",
    "$$ \\frac{x}{max - min}$$\n",
    "different features take similar scale (about -1<= x <=1). It helps gradient descent converge quicker. (e.g. the shape of the loss function contour will be regular shape if they have similar scale)<br>\n",
    "2. **mean normalization**: <br>\n",
    "$$ \\frac{x- \\mu}{\\sigma} $$ or $$ \\frac{x- \\mu}{max - min} $$ <br>\n",
    "3. it is important for especially **polynomial model**. \n",
    "\n",
    "**learning rate**<br>\n",
    "checking if gradient decent works? plot cost function vs iteration\n",
    "1. **observation**:for i iteration, got the weights, plug in cost function, then see plot of the cost function vs iteration to check if it works. \n",
    "2. **auto stop**, calculate the change of cost function, if it is less than the threshold, then stop \n",
    "3. if it goes up, it means not converging, it also indicate of **too large learning rate**.  \n",
    "4. if learning rate is small enough, J can converge. but too small learning rate takes too long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h3> Logistic regression </h3>\n",
    "adding sigmoid function \n",
    "$$z = \\theta ^T x $$ \n",
    "$$h(z) = \\frac{1}{1+ e^{-z}}$$\n",
    "h(z) is from 0 to 1, very similar to probability p(z). <br>\n",
    "\n",
    "**Decision boundary**, setting thredhold to be 0.5, which means h(z) > 0.5, we classify to be Class 1. This is equal to say we classify to be Class 1 when z > 0 or $\\theta ^ T x > 0 $. The hyperplane $\\theta^Tx=0$ will form a linear decision boundary on on the x plane. Notice that the decision boundary the property of $\\theta$ not x.<br>\n",
    "When using polynomial form, we can get a **non-linear** decision boundary like a circle $ 1 < x_1^2 + x_2^2 $ using $(1,x_1,x_2,x_1^2,x_2^2)$ as our predictor space. <br>\n",
    "\n",
    "** Solving**: not directly using least sqaure fit on h(z), because it is now become non-convex problem due to sigmoid function ( many local minimums). <br>\n",
    "Cost function ( using maximum likelyhood)<br>\n",
    "$$J(\\theta) = 1/m \\sum_i^m [(y^{(i)} \\log h(x^{(i)}) + (1-y^{(i)}) \\log (1-h(x^{(i)}))]$$\n",
    "Gradient decent<br> \n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial (\\theta_j)} $$\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial (\\theta_j)} = \\sum_i^m (h(x^{(i)})-y^{(i)})x_j^{(i)} $$\n",
    "<br>\n",
    "**Advanced optimization**:\n",
    "```matlab\n",
    "function [jVal, gradient] = costFunction(theta)\n",
    "% to compute jVal and its gradient\n",
    "\n",
    "% Call the function by \n",
    "options = optimset('GradObj', 'on', 'MaxIter', 100);\n",
    "initialTheta = zeros(2,1);\n",
    "[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Matlab </h3>\n",
    "matrix 2x2 matrix: x =[[1,2];[3,4]] <br>\n",
    "extend one column of b: x=[a[:,1],b[:,2]]  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
